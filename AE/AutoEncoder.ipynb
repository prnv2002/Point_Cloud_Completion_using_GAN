{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tqdm\n",
    "import torch\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyntcloud import PyntCloud\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        conv1 = [nn.Conv1d(3, 64, kernel_size=1), \n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.ReLU()]\n",
    "        conv2 = [nn.Conv1d(64, 128, kernel_size=1), \n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU()]\n",
    "        conv3 = [nn.Conv1d(128, 256, kernel_size=1), \n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU()]\n",
    "        conv4 = [nn.Conv1d(256, 128, kernel_size=1), \n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.AdaptiveMaxPool1d(1)]\n",
    "        self.conv1 = nn.Sequential(*conv1)\n",
    "        self.conv2 = nn.Sequential(*conv2)        \n",
    "        self.conv3 = nn.Sequential(*conv3)\n",
    "        self.conv4 = nn.Sequential(*conv4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_1 = self.conv1(x)\n",
    "        out_2 = self.conv2(out_1)\n",
    "        out_3 = self.conv3(out_2)\n",
    "        out_4 = self.conv4(out_3)\n",
    "        print(out_4.shape)\n",
    "        out_4 = out_4.view(-1, out_4.shape[1])\n",
    "        print(out_4.shape)\n",
    "        return out_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_points):\n",
    "        super(Decoder, self).__init__()\n",
    "        linear1 = [nn.Linear(128, 256), \n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU()]\n",
    "        linear2 = [nn.Linear(256, 256), \n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU()]\n",
    "        linear3 = [nn.Linear(256, 6144), \n",
    "                nn.ReLU()]\n",
    "        self.linear1 = nn.Sequential(*linear1)\n",
    "        self.linear2 = nn.Sequential(*linear2)\n",
    "        self.linear3 = nn.Sequential(*linear3)\n",
    "        self.num_points = num_points\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_1 = self.linear1(x)\n",
    "        out_2 = self.linear2(out_1)\n",
    "        out_3 = self.linear3(out_2)\n",
    "        \n",
    "        return out_3.view(-1, 3, self.num_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, num_points):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder(num_points)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        gfv = self.encoder(x)\n",
    "        out = self.decoder(gfv)\n",
    "        \n",
    "        return out, gfv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chamfer Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### For computing the distance matrix, we referred to the following link: https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChamferLoss(nn.Module):\n",
    "    def __init__(self, num_points):\n",
    "        super(ChamferLoss, self).__init__()\n",
    "        self.num_points = num_points\n",
    "        self.loss = torch.FloatTensor([0]).to(device)\n",
    "\n",
    "        \n",
    "    def forward(self, predict_pc, gt_pc):\n",
    "        z, _ = torch.min(torch.norm(gt_pc.unsqueeze(-2) - predict_pc.unsqueeze(-1),dim=1), dim=-2)\n",
    "            # self.loss += z.sum()\n",
    "        self.loss = z.sum() / (len(gt_pc)*self.num_points)\n",
    "\n",
    "        z_2, _ = torch.min(torch.norm(predict_pc.unsqueeze(-2) - gt_pc.unsqueeze(-1),dim=1), dim=-2)\n",
    "        self.loss += z_2.sum() / (len(gt_pc)*self.num_points)\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder(2048).to(device)\n",
    "chamfer_loss = ChamferLoss(2048).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '..latent_3d_points/data/shape_net_core_uniform_samples_2048/'\n",
    "\n",
    "list_point_clouds = np.load('../Load/numpy_arrays/list_point_subset.npy')\n",
    "list_point_clouds = list_point_clouds[:5000]\n",
    "np.save('list_point_subset_2.npy', list_point_clouds)\n",
    "\n",
    "X_train, X_test, _, _ = train_test_split(list_point_clouds, list_point_clouds, test_size=0.1, random_state=42)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointcloudDatasetAE(Dataset):\n",
    "    def __init__(self, root, list_point_clouds):\n",
    "        self.root = root\n",
    "        self.list_files = list_point_clouds\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.list_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        points = PyntCloud.from_file(self.list_files[index])\n",
    "        points = np.array(points.points)\n",
    "        points_normalized = (points - (-0.5)) / (0.5 - (-0.5))\n",
    "        points = points_normalized.astype(float)\n",
    "        points = torch.from_numpy(points)\n",
    "        \n",
    "        return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PointcloudDatasetAE(DATA_DIR, X_train)\n",
    "train_dataloader = DataLoader(train_dataset, num_workers=2, shuffle=False, batch_size=48)\n",
    "\n",
    "test_dataset = PointcloudDatasetAE(DATA_DIR, X_test)\n",
    "test_dataloader = DataLoader(test_dataset, num_workers=2, shuffle=False, batch_size=1)\n",
    "\n",
    "for i, data in enumerate(train_dataloader):\n",
    "    data = data.permute([0,2,1])\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1.0e-4\n",
    "momentum = 0.95\n",
    "optimizer_AE = torch.optim.Adam(autoencoder.parameters(), lr=lr, betas=(momentum, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Writer and Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = './ae_out_copy/'\n",
    "now =   str(datetime.datetime.now())\n",
    "\n",
    "if not os.path.exists(ROOT_DIR):\n",
    "    os.makedirs(ROOT_DIR)\n",
    "\n",
    "if not os.path.exists(ROOT_DIR + now):\n",
    "    os.makedirs(ROOT_DIR + now)\n",
    "\n",
    "LOG_DIR = ROOT_DIR + now + '/logs/'\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)\n",
    "\n",
    "OUTPUTS_DIR = ROOT_DIR  + now + '/outputs/'\n",
    "if not os.path.exists(OUTPUTS_DIR):\n",
    "    os.makedirs(OUTPUTS_DIR)\n",
    "\n",
    "MODEL_DIR = ROOT_DIR + now + '/models/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "summary_writer = SummaryWriter(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training')\n",
    "for epoch in range(1):\n",
    "    #autoencoder.train()\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        data = data.permute([0,2,1]).float().to(device)\n",
    "\n",
    "        optimizer_AE.zero_grad()\n",
    "        out_data, gfv = autoencoder(data)\n",
    "\n",
    "        loss = chamfer_loss(out_data, data)\n",
    "        loss.backward()\n",
    "        optimizer_AE.step()\n",
    "        \n",
    "        print('Epoch: {}, Iteration: {}, Content Loss: {}'.format(epoch, i, loss.item()))\n",
    "        summary_writer.add_scalar('Content Loss', loss.item())\n",
    "#         if i > 2:\n",
    "#             break\n",
    "        \n",
    "#     break\n",
    "    \n",
    "    torch.save(autoencoder.state_dict(), MODEL_DIR+'{}_ae_.pt'.format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder(2048).to(device)\n",
    "autoencoder.load_state_dict(torch.load('../Load/AE_weights/990_ae_.pt', map_location=torch.device('cpu'))) # Edit this to add the correct path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./eval_output/'):\n",
    "    os.makedirs('./eval_output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_test.shape[0]):\n",
    "        points = PyntCloud.from_file(X_test[i])\n",
    "        points = np.array(points.points)\n",
    "        points_normalized = (points - (-0.5)) / (0.5 - (-0.5))\n",
    "        points = points_normalized.astype(float)\n",
    "        points = torch.from_numpy(points).unsqueeze(0)\n",
    "        points = points.permute([0,2,1]).float().to(device)\n",
    "        print(points.shape)\n",
    "\n",
    "        autoencoder.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "                out_data, gfv = autoencoder(points)\n",
    "                loss = chamfer_loss(out_data, points)\n",
    "        print(loss.item())\n",
    "                \n",
    "        output = out_data[0,:,:]\n",
    "        output = output.permute([1,0]).detach().cpu().numpy()\n",
    "\n",
    "        inputt = points[0,:,:]\n",
    "        inputt = inputt.permute([1,0]).detach().cpu().numpy()\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax_x = fig.add_subplot(111, projection='3d')\n",
    "        x_ = output\n",
    "        ax_x.scatter(x_[:, 0], x_[:, 1], x_[:,2])\n",
    "        ax_x.set_xlim([0,1])\n",
    "        ax_x.set_ylim([0,1])\n",
    "        ax_x.set_zlim([0,1])\n",
    "        fig.savefig('eval_output/{}_{}.png'.format(i, 'out'))\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax_x = fig.add_subplot(111, projection='3d')\n",
    "        x_ = inputt\n",
    "        ax_x.scatter(x_[:, 0], x_[:, 1], x_[:,2])\n",
    "        ax_x.set_xlim([0,1])\n",
    "        ax_x.set_ylim([0,1])\n",
    "        ax_x.set_zlim([0,1])\n",
    "        fig.savefig('eval_output/{}_{}.png'.format(i, 'in'))\n",
    "\n",
    "        plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
